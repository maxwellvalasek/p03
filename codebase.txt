==== codebase.py ====
import os

def combine_code_files(output_filename="codebase.txt", root_dir="."):
    """
    Combines all Python code files (.py) in the specified directory and its
    subdirectories into a single text file, excluding __pycache__ directories.

    Args:
        output_filename (str): The name of the file to save the combined code.
        root_dir (str): The root directory to start searching from.
    """
    combined_code = []
    separator_template = "==== {file_path} ====\n"

    print(f"Starting code combination from root directory: {os.path.abspath(root_dir)}")
    found_files_count = 0

    for dirpath, dirnames, filenames in os.walk(root_dir):
        # --- Exclude __pycache__ directories ---
        # Method 1: Skip processing if the current dirpath is __pycache__ or inside one
        if "__pycache__" in dirpath.split(os.sep):
            continue
        # Method 2: Modify dirnames in-place to prevent os.walk from descending into __pycache__
        dirnames[:] = [d for d in dirnames if d != "__pycache__"]
        # --- ---

        for filename in filenames:
            if filename.endswith(".py"):
                file_path = os.path.join(dirpath, filename)
                # Use relative path in the separator for better readability
                relative_path = os.path.relpath(file_path, root_dir)
                print(f"Processing: {relative_path}")
                try:
                    # Use utf-8 encoding, but ignore errors for potentially mixed encodings
                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as infile:
                        content = infile.read()
                        combined_code.append(separator_template.format(file_path=relative_path))
                        combined_code.append(content)
                        # Add a couple of newlines for separation between file contents
                        combined_code.append("\n\n")
                        found_files_count += 1
                except Exception as e:
                    print(f"  Error reading file {file_path}: {e}")

    if not combined_code:
        print("No Python files found (excluding __pycache__).")
        return

    try:
        output_path = os.path.join(root_dir, output_filename) # Save in the root dir
        with open(output_path, 'w', encoding='utf-8') as outfile:
            outfile.write("".join(combined_code))
        print(f"\nSuccessfully combined {found_files_count} Python files into {output_path}")
    except Exception as e:
        print(f"\nError writing to output file {output_path}: {e}")

# --- Script Execution ---
if __name__ == "__main__":
    # You can change the root directory if needed, e.g., combine_code_files(root_dir="../project_folder")
    combine_code_files(output_filename="codebase.txt", root_dir=".")


==== api.py ====
from flask import jsonify, request, abort, Response
import json
import os
import requests
from datetime import datetime
import pandas as pd
from flask import stream_with_context

DATA_FILE = 'data.json'
connected_clients = set()

def init_api_routes(app):
    @app.route('/api/events')
    def events():
        def generate():
            last_data_count = 0
            
            while True:
                try:
                    # Get current data
                    table = get_data_as_table()
                    total = get_total_earnings()
                    today = get_earnings_today()
                    interactions_today = get_interactions_today()
                    total_interactions = get_total_interactions()
                    
                    # Check if data count has changed (new data added)
                    data_updated = total_interactions != last_data_count
                    last_data_count = total_interactions
                    
                    data = {
                        'table': table,
                        'total_earnings': total,
                        'earnings_today': today,
                        'interactions_today': interactions_today,
                        'total_interactions': total_interactions,
                        'data_updated': data_updated,
                        'timestamp': datetime.now().isoformat()
                    }
                    
                    yield f"data: {json.dumps(data)}\n\n"
                except Exception as e:
                    print(f"Error in event stream: {e}")
                    break
                
        return Response(stream_with_context(generate()), mimetype='text/event-stream')

    @app.route('/api/data', methods=['POST'])
    def handle_data():
        if not request.is_json:
            abort(400, description="Invalid JSON")
        
        data = request.get_json()
        interaction_type = data.get('interaction_type', '')
        ad_id = data.get('ad_id', '')
        timestamp = datetime.now().isoformat()
        earnings = 0.20  # New field for earnings
        new_entry = {
            'coordinates': '(37.8760, -122.2588)',  # Updated Berkeley coordinates
            'interaction_type': interaction_type,
            'ad_id': ad_id,
            'timestamp': timestamp,
            'earnings': earnings  # Add earnings to the new entry
        }

        if os.path.exists(DATA_FILE):
            with open(DATA_FILE, 'r+') as f:
                try:
                    existing_data = json.load(f)
                    if not isinstance(existing_data, list):
                        existing_data = [existing_data]
                except json.JSONDecodeError:
                    existing_data = []
                existing_data.append(new_entry)
                f.seek(0)
                json.dump(existing_data, f, indent=2)
                f.truncate()
        else:
            with open(DATA_FILE, 'w') as f:
                json.dump([new_entry], f, indent=2)

        # Get updated data
        updated_table = get_data_as_table()
        updated_total = get_total_earnings()
        updated_today = get_earnings_today()
        interactions_today = get_interactions_today()
        total_interactions = get_total_interactions()

        return jsonify({
            'message': 'Data received and saved successfully',
            'received_data': new_entry,
            'method_used': request.method,
            'updated_data': {
                'table': updated_table,
                'total_earnings': updated_total,
                'earnings_today': updated_today,
                'interactions_today': interactions_today,
                'total_interactions': total_interactions
            }
        }), 200

def make_post_request(url, interaction_type, ad_id):
    payload = {
        'coordinates': '(37.8760, -122.2588)',  # Updated Berkeley coordinates
        'interaction_type': interaction_type,
        'ad_id': ad_id
    }
    headers = {'Content-Type': 'application/json'}
    response = requests.post(url, json=payload, headers=headers)
    return response.json(), response.status_code

def get_data_as_table():
    if os.path.exists(DATA_FILE):
        with open(DATA_FILE, 'r') as f:
            try:
                data = json.load(f)
                if not isinstance(data, list):
                    data = [data]
                df = pd.DataFrame(data)
                if not df.empty:
                    summary = (
                        df.groupby('ad_id')
                        .size()
                        .reset_index(name='Interactions')
                    )
                    summary['Earnings'] = summary['Interactions'] * 0.20
                    # Keep earnings as a float
                    return summary.to_dict(orient='records')
                else:
                    return []
            except json.JSONDecodeError:
                return []
    else:
        return []

def get_total_earnings():
    # Calculate based on combined interactions * value
    total_interactions = get_total_interactions()
    return total_interactions * 0.20

def get_earnings_today():
    # Calculate based on combined interactions today * value
    interactions_today = get_interactions_today()
    return interactions_today * 0.20

def get_interactions_today():
    today_date = datetime.now().date()
    data_today_count = 0

    # Count today's entries in data.json
    if os.path.exists(DATA_FILE):
        try:
            with open(DATA_FILE, 'r') as f:
                data = json.load(f)
                if isinstance(data, list):
                    for entry in data:
                        try:
                            entry_ts = datetime.fromisoformat(entry.get('timestamp', '')).date()
                            if entry_ts == today_date:
                                data_today_count += 1
                        except (ValueError, TypeError):
                            continue # Ignore invalid timestamps
        except (json.JSONDecodeError, IOError):
            print(f"Error reading/parsing {DATA_FILE} for today's count")
            
    return data_today_count

def get_total_interactions():
    data_count = 0

    # Count total entries in data.json
    if os.path.exists(DATA_FILE):
        try:
            with open(DATA_FILE, 'r') as f:
                data = json.load(f)
                if isinstance(data, list):
                    data_count = len(data)
        except (json.JSONDecodeError, IOError):
             print(f"Error reading/parsing {DATA_FILE} for total count")
             
    return data_count


==== main.py ====
from flask import Flask, render_template, request, jsonify
import json
import os
import pandas as pd
from folium import Map, Element
import folium
from folium.plugins import HeatMap, MarkerCluster
from datetime import datetime
from collections import Counter
from api import init_api_routes, DATA_FILE, get_data_as_table, get_total_earnings, get_earnings_today
import ast
import tempfile
import shutil

app = Flask(__name__)

@app.route('/')
def show_data():
    if os.path.exists(DATA_FILE):
        with open(DATA_FILE, 'r') as f:
            try:
                data = json.load(f)
            except json.JSONDecodeError:
                data = []
    else:
        data = []

    ad_counts = Counter(entry.get('ad_id', '') for entry in data)
    return render_template('index.html',
                           data=data,
                           ad_counts=ad_counts,
                           earnings_table=get_data_as_table(),
                           total_earnings=get_total_earnings(),
                           earnings_today=get_earnings_today())

@app.route('/land')
def land_page():
    # Renders the land.html template
    return render_template('land.html')

@app.route('/send_data')
def send_data():
    return render_template('send_data.html')

@app.route('/map')
def map_view():
    combined_coords = []
    valid_coords_exist = False

    # 1. Read from coords.csv (Assuming this should still be included based on previous state)
    coords_file = 'coords.csv'
    if os.path.exists(coords_file):
        try:
            df_coords = pd.read_csv(coords_file)
            coords_csv_list = df_coords[['lat', 'lon']].dropna().values.tolist()
            combined_coords.extend(coords_csv_list)
            if coords_csv_list:
                 valid_coords_exist = True
        except Exception as e:
            print(f"Error processing {coords_file} for /map: {e}")

    # 2. Read from data.json
    if os.path.exists(DATA_FILE):
        try:
            with open(DATA_FILE, 'r') as f:
                all_data_json = json.load(f)
            if isinstance(all_data_json, list):
                for entry in all_data_json:
                    coords = parse_coordinate_string(entry.get('coordinates'))
                    if coords:
                        combined_coords.append(coords)
                        valid_coords_exist = True
        except (json.JSONDecodeError, IOError) as e:
            print(f"Error reading or parsing {DATA_FILE} for /map: {e}")

    if valid_coords_exist:
        min_lat = min(c[0] for c in combined_coords)
        max_lat = max(c[0] for c in combined_coords)
        min_lon = min(c[1] for c in combined_coords)
        max_lon = max(c[1] for c in combined_coords)
        padding = 0.001 
        if min_lat == max_lat: min_lat -= padding; max_lat += padding
        if min_lon == max_lon: min_lon -= padding; max_lon += padding
        fit_bounds_coords = [[min_lat, min_lon], [max_lat, max_lon]]
    else:
        fit_bounds_coords = [[37.8, -122.4], [37.9, -122.3]] # Default view

    m = Map(
        tiles="CartoDB positron",
        zoom_control=False,
        scrollWheelZoom=False,
        dragging=False,
        touchZoom=False,
        doubleClickZoom=False,
        boxZoom=False
    )
    
    m.fit_bounds(fit_bounds_coords)

    if combined_coords:
        HeatMap(combined_coords, radius=13, blur=12, min_opacity=0.3).add_to(m) # Adjusted radius from user prompt

        icon_create_function = '''
        function(cluster) {
            var markers = cluster.getAllChildMarkers();
            var totalValue = markers.length * 0.20;
            var displayValue = '$' + totalValue.toFixed(2);
            var style = `
                background: linear-gradient(135deg, #ffffff 60%, #e3f0ff 100%);
                height: 28px; padding: 0 10px; border-radius: 14%; display: flex;
                justify-content: center; align-items: center; font-size: 1.3em;
                font-weight: 900; color: #1a237e; box-shadow: 0 2px 10px rgba(30,60,120,0.18);
                text-shadow: 0 2px 8px #fff, 0 0 2px #1976d2, 0 0 8px #fff; user-select: none; opacity: 0.75;
            `;
            return new L.DivIcon({
                html: '<div style="' + style + '">' + displayValue + '</div>',
                className: 'my-custom-cluster-icon-with-bg',
                iconSize: [48, 48]
            });
        }
        '''
        marker_cluster = MarkerCluster(icon_create_function=icon_create_function).add_to(m)

        for lat, lon in combined_coords:
            folium.Marker(
                location=[lat, lon],
                popup=f"Lat: {lat:.4f}, Lon: {lon:.4f}"
            ).add_to(marker_cluster)

    # Atomic write to a static file
    map_filename = "templates/map_render.html"
    # Use try-finally to ensure temporary file is cleaned up on error during move
    tmp_file = None
    try:
        with tempfile.NamedTemporaryFile("w", dir="templates", delete=False, suffix=".html") as tmp_f:
            tmp_file = tmp_f.name # Store the temp file name
            m.save(tmp_file)
        # If save succeeds, move the file
        shutil.move(tmp_file, map_filename)
        tmp_file = None # Indicate move was successful
    finally:
        # Clean up the temp file only if the move failed and tmp_file exists
        if tmp_file and os.path.exists(tmp_file):
            try:
                os.remove(tmp_file)
            except OSError as e:
                print(f"Error removing temporary file {tmp_file}: {e}")

    return render_template("map_render.html")

@app.route('/map_today')
def map_today_view():
    # Cache-busting timestamp is ignored (available as request.args.get('t'))
    today_combined_coords = []
    valid_today_coords_exist = False
    today_date = datetime.now().date()
    
    # Load data from data.json and filter for today
    if os.path.exists(DATA_FILE):
        try:
            with open(DATA_FILE, 'r') as f:
                all_data_json = json.load(f)
            if isinstance(all_data_json, list):
                for entry in all_data_json:
                    try:
                        entry_ts = datetime.fromisoformat(entry.get('timestamp', '')).date()
                        if entry_ts == today_date:
                            coords = parse_coordinate_string(entry.get('coordinates'))
                            if coords:
                                today_combined_coords.append(coords)
                                valid_today_coords_exist = True
                    except (ValueError, TypeError):
                        continue  # Ignore invalid timestamps
        except (json.JSONDecodeError, IOError) as e:
            print(f"Error reading or parsing {DATA_FILE} for /map_today: {e}")

    # --- Force UC Berkeley campus bounding box ---
    fit_bounds_coords = [
        [37.8627, -122.2726],  # South-West corner
        [37.8790, -122.2453]   # North-East corner
    ]
    m = Map(
        tiles="CartoDB positron",
        # Enable interactive features
        zoom_control=True,
        scrollWheelZoom=True,
        dragging=True,
        touchZoom=True,
        doubleClickZoom=True,
        boxZoom=True
    )

    m.fit_bounds(fit_bounds_coords)
    
    # Add a timestamp to the HTML to prevent browser caching
    timestamp = datetime.now().strftime('%Y%m%d%H%M%S')
    map_filename = f"templates/map_today_render_{timestamp}.html"

    if today_combined_coords:
        HeatMap(today_combined_coords, radius=12, blur=12, min_opacity=0.3).add_to(m)

        icon_create_function = '''
        function(cluster) {
            var markers = cluster.getAllChildMarkers();
            var totalValue = markers.length * 0.20;
            var displayValue = '$' + totalValue.toFixed(2);
            var style = `
                background: linear-gradient(135deg, #ffffff 60%, #e3f0ff 100%);
                height: 28px; padding: 0 10px; border-radius: 14%;
                display: flex; justify-content: center; align-items: center;
                font-size: 1.3em; font-weight: 900; color: #1a237e;
                box-shadow: 0 2px 10px rgba(30,60,120,0.18);
                text-shadow: 0 2px 8px #fff, 0 0 2px #1976d2, 0 0 8px #fff;
                user-select: none; opacity: 0.75;
            `;
            return new L.DivIcon({
                html: '<div style="' + style + '">' + displayValue + '</div>',
                className: 'my-custom-cluster-icon-with-bg',
                iconSize: [48, 48]
            });
        }
        '''
        marker_cluster = MarkerCluster(icon_create_function=icon_create_function).add_to(m)

        for lat, lon in today_combined_coords:
            folium.Marker(
                location=[lat, lon],
                popup=f"Lat: {lat:.4f}, Lon: {lon:.4f}"
            ).add_to(marker_cluster)
            
    # Map remains static - no click/reset logic needed

    # Atomic write for today map
    map_filename_today = "templates/map_today_render.html"
    tmp_file_today = None
    try:
        with tempfile.NamedTemporaryFile("w", dir="templates", delete=False, suffix=".html") as tmp_f:
            tmp_file_today = tmp_f.name
            m.save(tmp_file_today)
        shutil.move(tmp_file_today, map_filename_today)
        tmp_file_today = None # Indicate move was successful
    finally:
        # Clean up the temp file only if the move failed
        if tmp_file_today and os.path.exists(tmp_file_today):
            try:
                os.remove(tmp_file_today)
            except OSError as e:
                print(f"Error removing temporary file {tmp_file_today}: {e}")

    return render_template("map_today_render.html")

# Initialize API routes
init_api_routes(app)

# Restore Helper function to parse coordinate string safely
def parse_coordinate_string(coord_str):
    try:
        # Handle format: "(37.875994, -122.3412217)"
        if isinstance(coord_str, str) and coord_str.startswith('(') and coord_str.endswith(')'):
            coords = ast.literal_eval(coord_str)
            if isinstance(coords, tuple) and len(coords) == 2 and all(isinstance(c, (int, float)) for c in coords):
                return list(coords)
                
        # Handle format: "37.875994,-122.3412217"
        elif isinstance(coord_str, str) and ',' in coord_str and not coord_str.startswith('('):
            parts = coord_str.split(',')
            if len(parts) == 2:
                try:
                    lat = float(parts[0].strip())
                    lon = float(parts[1].strip())
                    return [lat, lon]
                except ValueError:
                    pass
                    
        print(f"Warning: Could not parse coordinate string: {coord_str}")
        return None
    except (ValueError, SyntaxError, TypeError) as e:
        print(f"Error parsing coordinate string '{coord_str}': {e}")
        return None

if __name__ == '__main__':
    app.run(debug=True, host='0.0.0.0', port=3000)


