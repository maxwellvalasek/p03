==== api.py ====
from flask import jsonify, request, abort, Response
import json
import os
import requests
from datetime import datetime
import pandas as pd
from flask import stream_with_context

DATA_FILE = 'data.json'
connected_clients = set()

def init_api_routes(app):
    @app.route('/api/events')
    def events():
        def generate():
            while True:
                try:
                    # Get current data
                    table = get_data_as_table()
                    total = get_total_earnings()
                    today = get_earnings_today()
                    interactions_today = get_interactions_today()
                    total_interactions = get_total_interactions()
                    
                    data = {
                        'table': table,
                        'total_earnings': total,
                        'earnings_today': today,
                        'interactions_today': interactions_today,
                        'total_interactions': total_interactions
                    }
                    
                    yield f"data: {json.dumps(data)}\n\n"
                except Exception as e:
                    print(f"Error in event stream: {e}")
                    break
                
        return Response(stream_with_context(generate()), mimetype='text/event-stream')

    @app.route('/api/data', methods=['POST'])
    def handle_data():
        if not request.is_json:
            abort(400, description="Invalid JSON")
        
        data = request.get_json()
        interaction_type = data.get('interaction_type', '')
        ad_id = data.get('ad_id', '')
        timestamp = datetime.now().isoformat()
        earnings = 0.20  # New field for earnings
        new_entry = {
            'coordinates': '(37.875994, -122.3412217)',  # Hardcoded coordinates
            'interaction_type': interaction_type,
            'ad_id': ad_id,
            'timestamp': timestamp,
            'earnings': earnings  # Add earnings to the new entry
        }

        if os.path.exists(DATA_FILE):
            with open(DATA_FILE, 'r+') as f:
                try:
                    existing_data = json.load(f)
                    if not isinstance(existing_data, list):
                        existing_data = [existing_data]
                except json.JSONDecodeError:
                    existing_data = []
                existing_data.append(new_entry)
                f.seek(0)
                json.dump(existing_data, f, indent=2)
                f.truncate()
        else:
            with open(DATA_FILE, 'w') as f:
                json.dump([new_entry], f, indent=2)

        # Get updated data
        updated_table = get_data_as_table()
        updated_total = get_total_earnings()
        updated_today = get_earnings_today()
        interactions_today = get_interactions_today()
        total_interactions = get_total_interactions()

        return jsonify({
            'message': 'Data received and saved successfully',
            'received_data': new_entry,
            'method_used': request.method,
            'updated_data': {
                'table': updated_table,
                'total_earnings': updated_total,
                'earnings_today': updated_today,
                'interactions_today': interactions_today,
                'total_interactions': total_interactions
            }
        }), 200

def make_post_request(url, interaction_type, ad_id):
    payload = {
        'coordinates': '(37.875994, -122.3412217)',  # Hardcoded coordinates
        'interaction_type': interaction_type,
        'ad_id': ad_id
    }
    headers = {'Content-Type': 'application/json'}
    response = requests.post(url, json=payload, headers=headers)
    return response.json(), response.status_code

def get_data_as_table():
    if os.path.exists(DATA_FILE):
        with open(DATA_FILE, 'r') as f:
            try:
                data = json.load(f)
                if not isinstance(data, list):
                    data = [data]
                df = pd.DataFrame(data)
                if not df.empty:
                    summary = (
                        df.groupby('ad_id')
                        .size()
                        .reset_index(name='Interactions')
                    )
                    summary['Earnings'] = summary['Interactions'] * 0.20
                    # Keep earnings as a float
                    return summary.to_dict(orient='records')
                else:
                    return []
            except json.JSONDecodeError:
                return []
    else:
        return []

def get_total_earnings():
    # Calculate based on combined interactions * value
    total_interactions = get_total_interactions()
    return total_interactions * 0.20

def get_earnings_today():
    # Calculate based on combined interactions today * value
    interactions_today = get_interactions_today()
    return interactions_today * 0.20

def get_interactions_today():
    today_date = datetime.now().date()
    data_today_count = 0

    # Count today's entries in data.json
    if os.path.exists(DATA_FILE):
        try:
            with open(DATA_FILE, 'r') as f:
                data = json.load(f)
                if isinstance(data, list):
                    for entry in data:
                        try:
                            entry_ts = datetime.fromisoformat(entry.get('timestamp', '')).date()
                            if entry_ts == today_date:
                                data_today_count += 1
                        except (ValueError, TypeError):
                            continue # Ignore invalid timestamps
        except (json.JSONDecodeError, IOError):
            print(f"Error reading/parsing {DATA_FILE} for today's count")
            
    return data_today_count

def get_total_interactions():
    data_count = 0

    # Count total entries in data.json
    if os.path.exists(DATA_FILE):
        try:
            with open(DATA_FILE, 'r') as f:
                data = json.load(f)
                if isinstance(data, list):
                    data_count = len(data)
        except (json.JSONDecodeError, IOError):
             print(f"Error reading/parsing {DATA_FILE} for total count")
             
    return data_count


==== codebase.py ====
import os

def combine_code_files(output_filename="codebase.txt", root_dir="."):
    """
    Combines all Python code files (.py) in the specified directory and its
    subdirectories into a single text file, excluding __pycache__ directories.

    Args:
        output_filename (str): The name of the file to save the combined code.
        root_dir (str): The root directory to start searching from.
    """
    combined_code = []
    separator_template = "==== {file_path} ====\n"

    print(f"Starting code combination from root directory: {os.path.abspath(root_dir)}")
    found_files_count = 0

    for dirpath, dirnames, filenames in os.walk(root_dir):
        # --- Exclude __pycache__ directories ---
        # Method 1: Skip processing if the current dirpath is __pycache__ or inside one
        if "__pycache__" in dirpath.split(os.sep):
            continue
        # Method 2: Modify dirnames in-place to prevent os.walk from descending into __pycache__
        dirnames[:] = [d for d in dirnames if d != "__pycache__"]
        # --- ---

        for filename in filenames:
            if filename.endswith(".py"):
                file_path = os.path.join(dirpath, filename)
                # Use relative path in the separator for better readability
                relative_path = os.path.relpath(file_path, root_dir)
                print(f"Processing: {relative_path}")
                try:
                    # Use utf-8 encoding, but ignore errors for potentially mixed encodings
                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as infile:
                        content = infile.read()
                        combined_code.append(separator_template.format(file_path=relative_path))
                        combined_code.append(content)
                        # Add a couple of newlines for separation between file contents
                        combined_code.append("\n\n")
                        found_files_count += 1
                except Exception as e:
                    print(f"  Error reading file {file_path}: {e}")

    if not combined_code:
        print("No Python files found (excluding __pycache__).")
        return

    try:
        output_path = os.path.join(root_dir, output_filename) # Save in the root dir
        with open(output_path, 'w', encoding='utf-8') as outfile:
            outfile.write("".join(combined_code))
        print(f"\nSuccessfully combined {found_files_count} Python files into {output_path}")
    except Exception as e:
        print(f"\nError writing to output file {output_path}: {e}")

# --- Script Execution ---
if __name__ == "__main__":
    # You can change the root directory if needed, e.g., combine_code_files(root_dir="../project_folder")
    combine_code_files(output_filename="codebase.txt", root_dir=".")


==== main.py ====
from flask import Flask, render_template, request, jsonify
import json
import os
from folium import Map, Element
import folium
from folium.plugins import HeatMap, MarkerCluster
from datetime import datetime
from collections import Counter
from api import init_api_routes, DATA_FILE, get_data_as_table, get_total_earnings, get_earnings_today
import ast

app = Flask(__name__)

@app.route('/')
def show_data():
    if os.path.exists(DATA_FILE):
        with open(DATA_FILE, 'r') as f:
            try:
                data = json.load(f)
            except json.JSONDecodeError:
                data = []
    else:
        data = []

    ad_counts = Counter(entry.get('ad_id', '') for entry in data)
    return render_template('index.html',
                           data=data,
                           ad_counts=ad_counts,
                           earnings_table=get_data_as_table(),
                           total_earnings=get_total_earnings(),
                           earnings_today=get_earnings_today())

@app.route('/map')
def map_view():
    combined_coords = []
    valid_coords_exist = False

    # Load data from data.json
    if os.path.exists(DATA_FILE):
        try:
            with open(DATA_FILE, 'r') as f:
                all_data_json = json.load(f)
            if isinstance(all_data_json, list):
                for entry in all_data_json:
                    coords = parse_coordinate_string(entry.get('coordinates'))
                    if coords:
                        combined_coords.append(coords)
                        valid_coords_exist = True
        except (json.JSONDecodeError, IOError) as e:
            print(f"Error reading or parsing {DATA_FILE} for /map: {e}")

    # --- Static Map Setup (using combined data) ---
    if valid_coords_exist:
         min_lat = min(c[0] for c in combined_coords)
         max_lat = max(c[0] for c in combined_coords)
         min_lon = min(c[1] for c in combined_coords)
         max_lon = max(c[1] for c in combined_coords)
         padding = 0.001 
         if min_lat == max_lat: min_lat -= padding; max_lat += padding
         if min_lon == max_lon: min_lon -= padding; max_lon += padding
         fit_bounds_coords = [[min_lat, min_lon], [max_lat, max_lon]]
    else:
        fit_bounds_coords = [[37.8, -122.4], [37.9, -122.3]] # Default view

    m = Map(
            tiles="OpenStreetMap",
            zoom_control=False,
            scrollWheelZoom=False,
            dragging=False,
            touchZoom=False,
            doubleClickZoom=False,
            boxZoom=False
    )
    
    m.fit_bounds(fit_bounds_coords)

    if combined_coords:
        HeatMap(combined_coords, radius=15, blur=12, min_opacity=0.3).add_to(m)

        # Update icon function to use $0.20 per marker
        icon_create_function = '''
        function(cluster) {
            var markers = cluster.getAllChildMarkers();
            var totalValue = markers.length * 0.20; // Use $0.20 per interaction
            var displayValue = '$' + totalValue.toFixed(2);
            var style = `
                background: linear-gradient(135deg, #ffffff 60%, #e3f0ff 100%);
                height: 28px; padding: 0 10px; border-radius: 14%; display: flex;
                justify-content: center; align-items: center; font-size: 1.3em;
                font-weight: 900; color: #1a237e; box-shadow: 0 2px 10px rgba(30,60,120,0.18);
                text-shadow: 0 2px 8px #fff, 0 0 2px #1976d2, 0 0 8px #fff; user-select: none; opacity: 0.75;
            `;
            return new L.DivIcon({
                html: '<div style="' + style + '">' + displayValue + '</div>',
                className: 'my-custom-cluster-icon-with-bg',
                iconSize: [48, 48]
             });
        }
        '''
        marker_cluster = MarkerCluster(
            icon_create_function=icon_create_function
        ).add_to(m)

        # Add markers for all combined coords
        for lat, lon in combined_coords:
            folium.Marker(
                location=[lat, lon],
                popup=f"Lat: {lat:.4f}, Lon: {lon:.4f}" # Simplified popup
            ).add_to(marker_cluster)

    m.save("templates/map_render.html")
    return render_template("map_render.html")

@app.route('/map_today')
def map_today_view():
    today_combined_coords = []
    valid_today_coords_exist = False
    today_date = datetime.now().date()
    
    # Load data from data.json and filter for today
    if os.path.exists(DATA_FILE):
        try:
            with open(DATA_FILE, 'r') as f:
                all_data_json = json.load(f)
            if isinstance(all_data_json, list):
                for entry in all_data_json:
                    try:
                        entry_ts = datetime.fromisoformat(entry.get('timestamp', '')).date()
                        if entry_ts == today_date:
                             coords = parse_coordinate_string(entry.get('coordinates'))
                             if coords:
                                 today_combined_coords.append(coords)
                                 valid_today_coords_exist = True
                    except (ValueError, TypeError):
                        continue # Ignore invalid timestamps
        except (json.JSONDecodeError, IOError) as e:
            print(f"Error reading or parsing {DATA_FILE} for /map_today: {e}")

    # --- Static Map Setup for Today (using combined data) ---
    if valid_today_coords_exist:
         min_lat = min(c[0] for c in today_combined_coords)
         max_lat = max(c[0] for c in today_combined_coords)
         min_lon = min(c[1] for c in today_combined_coords)
         max_lon = max(c[1] for c in today_combined_coords)
         padding = 0.001 
         if min_lat == max_lat: min_lat -= padding; max_lat += padding
         if min_lon == max_lon: min_lon -= padding; max_lon += padding
         fit_bounds_coords = [[min_lat, min_lon], [max_lat, max_lon]]
    else:
        fit_bounds_coords = [[37.8, -122.4], [37.9, -122.3]] # Default view
        
    m = Map(
            tiles="OpenStreetMap",
            # Enable interactive features
            zoom_control=True,
            scrollWheelZoom=True,
            dragging=True,
            touchZoom=True,
            doubleClickZoom=True,
            boxZoom=True
    )

    m.fit_bounds(fit_bounds_coords)

    if today_combined_coords:
        HeatMap(today_combined_coords, radius=15, blur=12, min_opacity=0.3).add_to(m)

        # Use the same updated icon function ($0.20 per marker)
        icon_create_function = '''
        function(cluster) {
            var markers = cluster.getAllChildMarkers();
            var totalValue = markers.length * 0.20; // Use $0.20 per interaction
            var displayValue = '$' + totalValue.toFixed(2);
            var style = `
                background: linear-gradient(135deg, #ffffff 60%, #e3f0ff 100%);
                height: 28px; padding: 0 10px; border-radius: 14%; display: flex;
                justify-content: center; align-items: center; font-size: 1.3em;
                font-weight: 900; color: #1a237e; box-shadow: 0 2px 10px rgba(30,60,120,0.18);
                text-shadow: 0 2px 8px #fff, 0 0 2px #1976d2, 0 0 8px #fff; user-select: none; opacity: 0.75;
            `;
            return new L.DivIcon({
                html: '<div style="' + style + '">' + displayValue + '</div>',
                className: 'my-custom-cluster-icon-with-bg',
                iconSize: [48, 48]
             });
        }
        '''
        marker_cluster = MarkerCluster(
             icon_create_function=icon_create_function
        ).add_to(m)

        # Add markers for today's combined coords
        for lat, lon in today_combined_coords:
            folium.Marker(
                location=[lat, lon],
                popup=f"Lat: {lat:.4f}, Lon: {lon:.4f}" # Simplified popup
            ).add_to(marker_cluster)
            
    m.save("templates/map_today_render.html")
    return render_template("map_today_render.html")

# Initialize API routes
init_api_routes(app)

# Restore Helper function to parse coordinate string safely
def parse_coordinate_string(coord_str):
    try:
        # Handle format: "(37.875994, -122.3412217)"
        if isinstance(coord_str, str) and coord_str.startswith('(') and coord_str.endswith(')'):
            coords = ast.literal_eval(coord_str)
            if isinstance(coords, tuple) and len(coords) == 2 and all(isinstance(c, (int, float)) for c in coords):
                return list(coords)
                
        # Handle format: "37.875994,-122.3412217"
        elif isinstance(coord_str, str) and ',' in coord_str and not coord_str.startswith('('):
            parts = coord_str.split(',')
            if len(parts) == 2:
                try:
                    lat = float(parts[0].strip())
                    lon = float(parts[1].strip())
                    return [lat, lon]
                except ValueError:
                    pass
                    
        print(f"Warning: Could not parse coordinate string: {coord_str}")
        return None
    except (ValueError, SyntaxError, TypeError) as e:
        print(f"Error parsing coordinate string '{coord_str}': {e}")
        return None

if __name__ == '__main__':
    app.run(debug=True, host='0.0.0.0', port=3000)


==== tempCodeRunnerFile.py ====
import os

def combine_code_files(output_filename="codebase.txt", root_dir="."):
    """
    Combines all Python code files (.py) in the specified directory and its
    subdirectories into a single text file, excluding __pycache__ directories.

    Args:
        output_filename (str): The name of the file to save the combined code.
        root_dir (str): The root directory to start searching from.
    """
    combined_code = []
    separator_template = "==== {file_path} ====\n"

    print(f"Starting code combination from root directory: {os.path.abspath(root_dir)}")
    found_files_count = 0

    for dirpath, dirnames, filenames in os.walk(root_dir):
        # --- Exclude __pycache__ directories ---
        # Method 1: Skip processing if the current dirpath is __pycache__ or inside one
        if "__pycache__" in dirpath.split(os.sep):
            continue
        # Method 2: Modify dirnames in-place to prevent os.walk from descending into __pycache__
        dirnames[:] = [d for d in dirnames if d != "__pycache__"]
        # --- ---

        for filename in filenames:
            if filename.endswith(".py"):
                file_path = os.path.join(dirpath, filename)
                # Use relative path in the separator for better readability
                relative_path = os.path.relpath(file_path, root_dir)
                print(f"Processing: {relative_path}")
                try:
                    # Use utf-8 encoding, but ignore errors for potentially mixed encodings
                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as infile:
                        content = infile.read()
                        combined_code.append(separator_template.format(file_path=relative_path))
                        combined_code.append(content)
                        # Add a couple of newlines for separation between file contents
                        combined_code.append("\n\n")
                        found_files_count += 1
                except Exception as e:
                    print(f"  Error reading file {file_path}: {e}")

    if not combined_code:
        print("No Python files found (excluding __pycache__).")
        return

    try:
        output_path = os.path.join(root_dir, output_filename) # Save in the root dir
        with open(output_path, 'w', encoding='utf-8') as outfile:
            outfile.write("".join(combined_code))
        print(f"\nSuccessfully combined {found_files_count} Python files into {output_path}")
    except Exception as e:
        print(f"\nError writing to output file {output_path}: {e}")

# --- Script Execution ---
if __name__ == "__main__":
    # You can change the root directory if needed, e.g., combine_code_files(root_dir="../project_folder")
    combine_code_files(output_filename="codebase.txt", root_dir=".")


